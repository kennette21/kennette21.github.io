I"ƒ<h2 id="discoverd-watson-speech-to-text-service">Discoverd Watson Speech to Text Service</h2>
<p>Easy enough to use. things to figure</p>

<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />How to get from audio in mic to watson.</li>
</ul>

<p>Things to consider:
watson detect options:</p>
<ul>
  <li>Speech detector sensitivity</li>
  <li>keywords. how does the api return dems? Lets see.</li>
</ul>

<p>Lets call it a night, it is 00:27. Not too late but certainly later than is great. Would like to be going to sleep earlier these days to have more productive mornings. To summarize this evenings progress and what is to come:</p>

<h2 id="this-evening">This Evening:</h2>
<h1 id="progress">Progress:</h1>
<ol>
  <li>Doing Speech to Text translation completely on The Raspbery Pi with the 6 mic Array</li>
  <li>Using IBM Watson S2T</li>
  <li>Identify Ability to send Keywords to Watson Request</li>
</ol>

<h1 id="ideas">Ideas:</h1>
<ol>
  <li>Go? Seems really simple to use th Watson API in go
    <ul>
      <li>worth a 20 minute delve into go. It was 3 lines</li>
    </ul>
  </li>
  <li>Be sure to check up on Watson S2T API docs. Many cool filtration methods.</li>
</ol>

<h1 id="up-next">Up Next:</h1>
<ol>
  <li>Consider how to bring the tiered activation word arrays over.
    <ul>
      <li>do you just cat all the arrays together and pass to watson? (i think the limit is 1000)</li>
      <li>Start with simple phrases.</li>
    </ul>
    <ul>
      <li><em>IDEA</em> oh could have an add phrase function!! 
    - <em>e.g.</em> activate words = [LIGHTS_ACTIVATE,NOTES_ACTIVATE,AUDIO_BOOK_ACTIVATEâ€¦] 
action words = [ON, BEGIN, ] ** are all action words unique to the category thoughâ€¦ this certainly needs itâ€™s own time</li>
    </ul>
  </li>
  <li>
    <p>Doing the speech detection LIVE!</p>
  </li>
  <li>Using python to get an Audio Stream!
    <ul>
      <li>sending that Audio stream to Porcupine to notice Jarvis word</li>
    </ul>
  </li>
  <li>On recognize Jarvis: send the -5s +5s time window from Jarvis to IBM Watson wthe keyword request
    <ul>
      <li>1st step: save the audio file, end the file (probably slow)</li>
      <li>2nd step: stream the audio file</li>
    </ul>
  </li>
  <li>
    <p>On API response, do the proper action. Control the lights.</p>
  </li>
  <li>Once lights are working, next steps would be:
    <ul>
      <li>recording audio notes -&gt; transcribing (interesting quality analysis..?)</li>
      <li>Food recomendation (hurdle here is content collection. Collect sophisticated list of stuff)</li>
      <li>Video Record start and stop</li>
    </ul>
    <ul>
      <li>3D print mount for PI HQ Cam, or Pixel. (BOTH?)</li>
    </ul>
  </li>
</ol>

<h2 id="ps">P.S.</h2>
<p>Working on this little pi is kind of fun. I do not know how to use the system as well as the mac and it is a bit lower lever. Using Vim and thi bare bones Thonny Editor. Feels good. Kind of get lost on some tangents trying to improve my process. Also makes me settle for simple productivity like Vim. Would like to get to the point where I am most efficient with tools like this.</p>

:ET